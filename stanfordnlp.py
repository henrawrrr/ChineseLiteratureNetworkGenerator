# -*- coding: utf-8 -*-
"""StanfordNLP

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tu46hULUU8W2CMiQcbDu-2VvFb3l7qTf
"""

!pip install stanfordnlp

# Import stanfordnlp
import stanfordnlp

# Download the Stanford CoreNLP Java library and unzip it to a ./corenlp folder
!echo "Downloading CoreNLP..."
!wget "http://nlp.stanford.edu/software/stanford-corenlp-full-2018-10-05.zip" -O corenlp.zip
!unzip corenlp.zip
!mv ./stanford-corenlp-full-2018-10-05 ./corenlp

# Set the CORENLP_HOME environment variable to point to the installation location
import os
os.environ["CORENLP_HOME"] = "./corenlp"

from stanfordnlp.server import CoreNLPClient

# Construct a CoreNLPClient with some basic annotators, a memory allocation of 4GB, and port number 9001
client = CoreNLPClient(annotators=['tokenize','ssplit', 'pos', 'lemma', 'ner'], memory='4G', endpoint='http://localhost:9001')
print(client)

# Start the background server and wait for some time
# Note that in practice this is totally optional, as by default the server will be started when the first annotation is performed
client.start()
import time; time.sleep(10)

!ps -o pid,cmd | grep java

from google.colab import drive
drive.mount('/content/gdrive')

with open('/content/gdrive/My Drive/Colab Notebooks/chapter1.txt', 'r') as file:
  data = file.read().replace('\n', '')

#data = "Such were some of various omens. Emperor Ling, greatly moved by these signs of the displeasure of Heaven, issued an edict asking his ministers for an explanation of the calamities and marvels."

document = client.annotate(data)
print(type(document))

# Iterate over all detected entity mentions
print("{:30s}\t{}".format("Mention", "Type"))
listofchar = []
for sent in document.sentence:
    for m in sent.mentions:
        #print(type(m.entityType))
        #print("{:30s}\t{}".format(m.entityMentionText, m.entityType))
        if m.entityType[0] is "P":
          if m.entityMentionText not in listofchar:
            listofchar.append(m.entityMentionText)

#!pip install pycorenlp
#from pycorenlp import StanfordCoreNLP
nlp = CoreNLPClient(annotators=['tokenize','ssplit', 'pos', 'lemma', 'ner'], memory='4G', endpoint='http://localhost:9001')

def resolve(corenlp_output):
    """ Transfer the word form of the antecedent to its associated pronominal anaphor(s) """
    for coref in corenlp_output['corefs']:
        mentions = corenlp_output['corefs'][coref]
        antecedent = mentions[0]  # the antecedent is the first mention in the coreference chain
        for j in range(1, len(mentions)):
            mention = mentions[j]
            if mention['type'] == 'PRONOMINAL':
                # get the attributes of the target mention in the corresponding sentence
                target_sentence = mention['sentNum']
                target_token = mention['startIndex'] - 1
                # transfer the antecedent's word form to the appropriate token in the sentence
                corenlp_output['sentences'][target_sentence - 1]['tokens'][target_token]['word'] = antecedent['text']


def print_resolved(corenlp_output):
    """ Print the "resolved" output """
    finishedstring= ""
    possessives = ['hers', 'his', 'their', 'theirs']
    for sentence in corenlp_output['sentences']:
        for token in sentence['tokens']:
            output_word = token['word']
            # check lemmas as well as tags for possessive pronouns in case of tagging errors
            if token['lemma'] in possessives or token['pos'] == 'PRP$':
                output_word += "'s"  # add the possessive morpheme
            output_word += token['after']
            finishedstring += output_word
    return finishedstring

listofstrings = []
with open('/content/gdrive/My Drive/Colab Notebooks/chapter1.txt', 'r') as file:
    listofstrings = file.readlines()

bigstring = ""
for string in listofstrings:
  output = nlp.annotate(string, properties= {'annotators':'dcoref','outputFormat':'json','ner.useSUTime':'false'})

  resolve(output)

  #print('\nOriginal:', string)
  #print('\nResolved: ', end='')
  bigstring += print_resolved(output)
print(bigstring)

import nltk
from nltk import sent_tokenize
nltk.download('punkt')
senlist = sent_tokenize(bigstring)
print(senlist)

print(listofchar)

def getNum(s):
  if "Positive" in s:
    return 1
  if "Negative" in s:
    return -1
  if "Neutral" in s:
    return 0
  return 0

listofchar.remove('his')
listofchar.remove("His")
listofchar.remove('He')
listofchar.remove('he')
listofchar.remove('him')
listofchar.remove("Him")
for t in listofchar:
  if "." in t:
    listofchar.remove(t)
Graph = [[0 for x in range(len(listofchar))] for y in range(len(listofchar))] 

for i in range(len(listofchar)):
  for j in range(len(listofchar)):
    Graph[i][j] = 0 
for sentence in senlist:
  print(sentence)
  for x in range(len(listofchar)):
    y = x + 1
    for y in range(len(listofchar)):
      if listofchar[x] in sentence and listofchar[y] in sentence:
        result = sentiment.annotate(sentence, properties={ 'annotators': 'sentiment, ner, pos', 'outputFormat': 'json', 'timeout': 60000}) 
        for s in result['sentences']:
          score = (s['sentimentValue'], s['sentiment'])
          num = getNum(score[1])
          Graph[x][y] += num
          Graph[y][x] += num

import matplotlib.pyplot as plt
import matplotlib.colors as colors
import matplotlib.cm as cmx
import networkx as nx
import numpy as np
dic = {}
for x in range(len(listofchar)):
  dic[x] = listofchar[x]

G = nx.from_numpy_matrix(np.array(Graph)) 
H = nx.relabel_nodes(G, dic)
edgenum = len(H.edges)
values = range(edgenum)
jet = cm = plt.get_cmap('jet') 
cNorm  = colors.Normalize(vmin=0, vmax=values[-1])
scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=jet)
colorList = []

for i in range(edgenum):
      colorVal = scalarMap.to_rgba(values[i])
      colorList.append(colorVal)

nx.draw(H,edge_color=colorList, with_labels= True)
plt.show()
#nx.draw(H, pos, node_color='b', edgelist=edges, edge_color=weights, width=10.0, edge_cmap=plt.cm.Blues)
#nx.draw(H, with_labels=True)

# Shut down the background CoreNLP server
client.stop()

time.sleep(10)
!ps -o pid,cmd | grep java